ğŸ“œ Overview
The Turkish Joke Generator creates culturally coherent Turkish jokes across multiple categories (Nasreddin Hoca, Temel, and General jokes). The project combines modern natural language generation techniques with Turkish linguistic patterns to produce humorous content. What makes this project unique is the implementation and comparison of two different machine learning approaches:

Fine-tuned GPT-2 Model: A transformer-based language model adapted specifically for Turkish joke generation
Custom LSTM Model: A character-level recurrent neural network built from scratch for Turkish text generation

âœ¨ Features

Multiple Joke Categories: Generate jokes in specific categories (Nasreddin Hoca, Temel, General) or get a random selection
Dual Model Architecture: Compare outputs from both GPT-2 and LSTM models
Quality Assurance: Advanced scoring algorithm to ensure joke quality and coherence
Similarity Detection: Ensures generated jokes are original and not duplicated from the training data
Responsive Design: User-friendly interface that works across devices
Intelligent Post-Processing: Cleanup and enhancement of generated text for improved readability

ğŸ› ï¸ Technologies

Backend: Python, Flask
Frontend: HTML5, CSS3, Bootstrap, JavaScript
Machine Learning: PyTorch, Transformers (Hugging Face)
Development: Git, GitHub
Testing: Python unittest
Project Management: Scrum, Trello

ğŸ“‹ Prerequisites

Python 3.8 or higher
pip package manager
8GB RAM (recommended for model loading)
2GB available disk space

ğŸ”§ Installation

Clone the repository
bashgit clone (https://github.com/Maltepe-University-SWEng/term-project-team-7)

cd turkish-joke-generator

Create and activate a virtual environment
bashpython -m venv .venv

# On Windows
.venv\Scripts\activate

# On macOS/Linux
source .venv/bin/activate

Install required dependencies
bashpip install -r requirements.txt

Verify data and model directories
data/               # Should contain joke datasets
â”œâ”€â”€ nasreddin.json
â”œâ”€â”€ temel.json
â””â”€â”€ genel.json

models/             # Should contain pre-trained models
â”œâ”€â”€ fikra_model/    # GPT-2 fine-tuned model
â””â”€â”€ lstm_model/     # Custom LSTM model

Start the application
bashpython app.py

Access the web interface
Open your browser and navigate to http://localhost:5000

ğŸš€ Usage

Select model type (GPT-2 or LSTM)
Choose joke category (Nasreddin Hoca, Temel, General, or Random)
Click "FÄ±kra Ãœret" (Generate Joke) button
Read and enjoy your AI-generated Turkish joke
Click "Modelleri KarÅŸÄ±laÅŸtÄ±r" (Compare Models) to see output from both models simultaneously

ğŸ§ª Testing
Run the comprehensive test suite with:
bashpython -m unittest test_fikra_generator.py
The test suite includes unit tests, integration tests, and API tests to ensure system reliability.
ğŸ“‚ Project Structure
turkish-joke-generator/
â”œâ”€â”€ data/                   # Joke datasets
â”œâ”€â”€ models/                 # Pre-trained models
â”œâ”€â”€ static/                 # Static assets and images
â”œâ”€â”€ templates/              # HTML templates
â”œâ”€â”€ app.py                  # Main Flask application
â”œâ”€â”€ check_joke.py           # Similarity checking tool
â””â”€â”€ test_fikra_generator.py # Test suite
ğŸ‘¥ Team Members

Ã–mer Faruk Ã–zer - Scrum Master & Model Developer
Furkan Aksoy - Lead Developer
Mehmet GÃ¼zel - Back-End Developer
Tamay Yazgan - QA Tester
Emre SarÄ± - Front-End Developer
Yaren YÄ±ldÄ±z - Data Scientist

ğŸŒŸ Acknowledgements
This project was developed as part of the Software Project Management course (SE403) at Maltepe University under the guidance of Professor Ensar GÃ¼l.
ğŸ“„ License
This project is licensed under the MIT License - see the LICENSE file for details.

Â© 2025 Turkish Joke Generator - Maltepe University SE403 Team-7
